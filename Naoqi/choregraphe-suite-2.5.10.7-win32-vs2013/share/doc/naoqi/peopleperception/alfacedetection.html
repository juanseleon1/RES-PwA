<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>ALFaceDetection &mdash; Aldebaran 2.5.9.8-r3 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2.5.9.8-r3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="Aldebaran 2.5.9.8-r3 documentation" href="../../index.html" />
    <link rel="up" title="NAOqi People Perception" href="index.html" />
    <link rel="next" title="ALFaceDetection API" href="alfacedetection-api.html" />
    <link rel="prev" title="ALFaceCharacteristics API" href="alfacecharacteristics-api.html" />
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115894784-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115894784-1');
</script>

<script type="text/javascript" src="https://cloud.aldebaran-robotics.com/static/js/topbar.js"></script>
<style>
div#hd::after {
  
  
  content: 'NAOqi 2.5';
  
  
  
  position: absolute;
  margin-top: -54px;
  right: -4px;
  font-size: 125%;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -o-transform: rotate(45deg);
  transform: rotate(45deg);
  }
</style>
<script>

$(window).ready(function () {

    //Aldebaran Top bar
     var barLinks = [];
     barLinks.push({'name':'Aldebaran Site', 'url':'http://www.aldebaran-robotics.com', 'click':'', 'img':'https://cloud.aldebaran-robotics.com/static/img/aldeb.png'});
     barLinks.push({'name':'Documentation', 'url':'../../index.html', 'click':"", 'img':''});
     function ShowBar(name, email, usertype) {
        var barParams = {
            'name'    : name,
            'email'   : email,
            'usertype': usertype,
            'loginfct': "FctLogin"
        }
        try { InitTopBar(barParams, barLinks); } catch (e) { console.log('Top Bar Init Failed'); }
    }
    ShowBar();

    var width_label = 0;
    $('dl.function-index dt > span').each(function () {
        $(this).css('width', 'auto');
        width_label = Math.max(width_label, $(this).width());
    }).width(width_label + 30);
    $('.sig-paren').width('auto');

    // first level navigation

    var buttonIds = [".naoqi", "pepper", "nao", "romeo"];
    for(id in buttonIds){
        $(id).removeClass("active");
    }
    //Aldebaran project
    if ($('.toctree-l1.current a').text().indexOf("Romeo ")==0){
        $(".romeo").toggleClass('active');
    }
    else if ($('.toctree-l1.current a').text().indexOf("Pepper ")==0){
        $(".pepper").toggleClass('active');
    }
    else if ($('.toctree-l1.current a').text().indexOf("NAO ")==0){
        $(".nao").toggleClass('active');
    }
    else if($('.toctree-l1.current a').text().indexOf("NAOqi ")==0){
        $(".naoqi").toggleClass('active');
    }

    //qibuild project
    if ($('.toctree-l1.current a').text().indexOf("Welcome to qiBuild documentation !")==0){
        $(".beginner").toggleClass('active');
    }
    else if ($('.toctree-l1.current a').text().indexOf("Advanced qibuild usage")==0){
        $(".advanced").toggleClass('active');
    }
    else if ($('.toctree-l1.current a').text().indexOf("Hacking qiBuild")==0){
        $(".hacking").toggleClass('active');
    }

    // add "On this page", add cssClasses
    if($('.yui-g .section h1').length > 0){
        $('.yui-g .section h1:first').addClass("titleWrapper");
        $('.yui-g .section h1:first').after($("#on-this-page").html())
    }
    else if($('.yui-g .section h2').length > 0){
        $('.yui-g .section h2:first').addClass("titleWrapper");
        $('.yui-g .section h2:first').after($("#on-this-page").html())
    }
    //remove first element on this page
    if($("#on-this-page").length > 0){
        var doms = $(".yui-g .section :first").nextUntil("#toc-list");
        doms = doms.add($("#toc-list"));
        doms.wrapAll('<div class="iNavWrapper"></div>');
        $("#toc-list ul li a:first").remove()
        $("#toc-list ul:first").replaceWith($("#toc-list ul li").html())
    }
    $("#toc-list").hide();
    $("#otp-link").click(function(){
        $("#toc-list").slideToggle();
        if($("h2#otp-link").hasClass("change-before")){
            $("h2#otp-link").removeClass("change-before")
        }
        else{
            $("h2#otp-link").addClass("change-before")
        }
    });

    if($("a.current.reference.internal").length>0){
        var left = $("a.current.reference.internal").position().left-1;
        var width = $("a.current.reference.internal").width();
        var offset = 51;
        var sidebarWidth = 339;
        var right = sidebarWidth - (left + width + offset);
        if($("a.current.reference.internal").height() <= 15){
            $("a.current.reference.internal").css("white-space","nowrap");
            $("a.current.reference.internal").css({"backgroundColor":"#0F2939","paddingTop":"2px", "paddingBottom":"2px","paddingLeft":left+"px","marginLeft":"-"+left+"px", "paddingRight":right+"px","marginRight":"-"+right+"px", "boxShadow":"0px 0px 1px rgb(15, 41, 57)"});
        }
        else{
            $("a.current.reference.internal").css({"float":"right","backgroundColor":"#0F2939","paddingTop":"2px", "paddingBottom":"2px","paddingLeft":left+"px","marginLeft":"-"+left+"px", "paddingRight":right+"px","marginRight":"-"+right+"px", "boxShadow":"0px 0px 1px rgb(15, 41, 57)"});
            left = $("a.current.reference.internal").position().left-1;
            width = $("a.current.reference.internal").width();
            right = sidebarWidth - (left + width + offset);
            $("a.current.reference.internal").css({"float":"right","backgroundColor":"#0F2939","paddingTop":"2px", "paddingBottom":"2px","paddingLeft":left+"px","marginLeft":"-"+left+"px", "paddingRight":right+"px","marginRight":"-"+right+"px", "boxShadow":"0px 0px 1px rgb(15, 41, 57)"});
        }
        $("a.current.reference.internal").parent().css("list-style-type","none");
    }

    //back to top
    var offset = 300,
    //browser window scroll (in pixels) after which the "back to top" link opacity is reduced
    offset_opacity = 1200,
    //duration of the top scrolling animation (in ms)
    scroll_top_duration = 700;
    //grab the "back to top" link
    var back_to_top = $('.cd-top');

    //hide or show the "back to top" link
    $(window).scroll(function(){
        //back to top button
        ( $(this).scrollTop() > offset ) ? back_to_top.addClass('cd-is-visible') : back_to_top.removeClass('cd-is-visible cd-fade-out');
        if( $(this).scrollTop() > offset_opacity ) {
            back_to_top.addClass('cd-fade-out');
        }
    });

    //smooth scroll to top
    back_to_top.click(function(event){
        event.preventDefault();
        $('body,html').animate({
            scrollTop: 0 ,
        }, scroll_top_duration
        );
    });
    //add show source button

    //replace "go" with "search"
    $("#searchbox form input[type=submit]").val("Search")

    //trigger click on version triangle to jump to whats new
    $("#hd").click(function(e){if(e.pageX >= this.offsetWidth && e.pageY<120){$(".whatsnew")[0].click()}})
})

</script>


  </head>
  <body role="document">

    <div class="document">
  <div id="custom-doc" class="yui-t3">
    <div id="hd">
      
      <h1><a href="../../index.html">SoftBank Robotics documentation</a>
      
      
      <span><a class="whatsnew" href="../../news/index.html" >
      
          What's new in NAOqi 2.5?
      
      </a></span>
      
      </h1>
      <div id="global-nav">
        
        <a class="naoqi" title="NAOqi Developer guide" href="../../index_dev_guide.html">NAOqi</a>
        <a class="pepper" title="Pepper documentation" href="../../home_pepper.html">Pepper</a>
        <a class="nao" title="NAO documentation" href="../../home_nao.html">NAO</a>
        <a class="romeo" title="Romeo Documentation" href="../../home_romeo.html">Romeo</a>
        
        
        
        <div class="nav">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script></div>
      </div>

    </div>
    <main class="cd-container">
        <div id="bd">
          <div id="yui-main">
            <div class="yui-b">
              <div class="yui-g" id="naoqi-peopleperception-alfacedetection">
                
  <div class="section" id="alfacedetection">
<span id="id1"></span><h1>ALFaceDetection<a class="headerlink" href="#alfacedetection" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p><a class="reference internal" href="index.html#naoqi-peopleperception"><span>NAOqi People Perception</span></a> - Overview | <a class="reference internal" href="alfacedetection-api.html#alfacedetection-api"><span>API</span></a> |
<a class="reference internal" href="alfacedetection-tuto.html#alfacedetection-tuto"><span>Tutorials</span></a></p>
<hr class="docutils" />
<div class="section" id="what-it-does">
<h2>What it does<a class="headerlink" href="#what-it-does" title="Permalink to this headline">¶</a></h2>
<p><strong>ALFaceDetection</strong> is a vision module in which the robot tries to detect,
and optionally recognize, faces in front of him.</p>
</div>
<div class="section" id="how-it-works">
<h2>How it works<a class="headerlink" href="#how-it-works" title="Permalink to this headline">¶</a></h2>
<p><strong>ALFaceDetection</strong> is based on a face detection/recognition solution provided
by <strong>OMRON</strong>.</p>
<div class="section" id="face-detection">
<h3>Face detection<a class="headerlink" href="#face-detection" title="Permalink to this headline">¶</a></h3>
<p>Face detection detects faces and provides their position, as well as a list of
angular coordinates for important faces features (eyes, nose, mouth).</p>
</div>
<div class="section" id="recognition">
<h3>Recognition<a class="headerlink" href="#recognition" title="Permalink to this headline">¶</a></h3>
<p>To make the robot not only detect but also recognize people, a learning stage is necessary.
For further details, see: <a class="reference internal" href="#alfacedetection-learning-stage"><span>Learning stage for recognition</span></a>.</p>
<p>Recognition feature returns for every image the names of people that are recognized.</p>
<div class="section" id="threshold">
<span id="id2"></span><h4>Threshold<a class="headerlink" href="#threshold" title="Permalink to this headline">¶</a></h4>
<p>Each name is associated to a matching score between 0 and 1. A higher score means a
higher certainty. Only results with a score above a given threshold are considered,
which means that it is possible to configure <strong>ALFaceDetection</strong> to be more or less strict.
A low threshold value means that the module often returns results but they can be wrong.
A higher value means that only matches with a high certainty are considered,
reducing the risk of errors, but it might be harder to get any result at all.</p>
</div>
<div class="section" id="temporal-filter">
<h4>Temporal filter<a class="headerlink" href="#temporal-filter" title="Permalink to this headline">¶</a></h4>
<p>In addition, there is temporal filter output to easily build higher
level features using recognition. Indeed we don&#8217;t want the robot to say &#8220;Hello Michel&#8221; several
times per second, so someone&#8217;s name is only be output the first time he is recognized
and is placed in a short term memory. This memory is kept as long as some faces
is not only recognized but detected by the robot.
As soon as there are more than 4 seconds without detecting any face, the short term
memory is cleared and Michel name will be output again if the robot encounters him.
This is that output that is used in the Choregraphe <strong>Face Reco</strong> box.</p>
</div>
</div>
<div class="section" id="facedetected-event">
<span id="facedetected-event-value"></span><h3>FaceDetected Event<a class="headerlink" href="#facedetected-event" title="Permalink to this headline">¶</a></h3>
<p>Once <strong>ALFaceDetection</strong> is started, the event <a class="reference internal" href="alfacedetection-api.html#FaceDetected" title="FaceDetected"><code class="xref naoqi naoqi-event docutils literal"><span class="pre">FaceDetected()</span></code></a>
returns a value organized as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">FaceDetected</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">TimeStamp</span><span class="p">,</span>
  <span class="p">[</span> <span class="n">FaceInfo</span><span class="p">[</span><span class="n">N</span><span class="p">],</span> <span class="n">Time_Filtered_Reco_Info</span> <span class="p">],</span>
  <span class="n">CameraPose_InTorsoFrame</span><span class="p">,</span>
  <span class="n">CameraPose_InRobotFrame</span><span class="p">,</span>
  <span class="n">Camera_Id</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>TimeStamp</strong>: this field is the time stamp of the image that was used to perform the detection.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">TimeStamp</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">TimeStamp_Seconds</span><span class="p">,</span>
  <span class="n">Timestamp_Microseconds</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>FaceInfo</strong>: for each detected face, we have one FaceInfo field.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">FaceInfo</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">ShapeInfo</span><span class="p">,</span>
  <span class="n">ExtraInfo</span><span class="p">[</span><span class="n">N</span><span class="p">]</span>
<span class="p">]</span>
</pre></div>
</div>
<p><em>ShapeInfo</em>: shape information about a face.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ShapeInfo</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="mi">0</span><span class="p">,</span>
  <span class="n">alpha</span><span class="p">,</span>
  <span class="n">beta</span><span class="p">,</span>
  <span class="n">sizeX</span><span class="p">,</span>
  <span class="n">sizeY</span>
<span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>alpha</strong> and <strong>beta</strong> represent the face&#8217;s location in terms of camera angles</li>
<li><strong>sizeX</strong> and <strong>sizeY</strong> are the face&#8217;s size in camera angle</li>
</ul>
<p><em>ExtraInfo</em>: shape information about a face.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ExtraInfo</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">faceID</span><span class="p">,</span>
  <span class="n">scoreReco</span><span class="p">,</span>
  <span class="n">faceLabel</span><span class="p">,</span>
  <span class="n">leftEyePoints</span><span class="p">,</span>
  <span class="n">rightEyePoints</span><span class="p">,</span>
  <span class="n">unused</span><span class="p">,</span> <span class="c"># for backward-compatibility issues</span>
  <span class="n">unused</span><span class="p">,</span>
  <span class="n">nosePoints</span><span class="p">,</span>
  <span class="n">mouthPoints</span>
<span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>faceID</strong> represents the ID number for the face</li>
<li><strong>scoreReco</strong> is the score returned by the recognition process (the higher, the better)</li>
<li><strong>faceLabel</strong> is the name of the recognized face if the face has been recognized</li>
<li><strong>leftEyePoints</strong> and <strong>rightEyePoints</strong> provide interesting points positions for the eyes (given in camera angles)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">EyePoints</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">eyeCenter_x</span><span class="p">,</span>
  <span class="n">eyeCenter_y</span><span class="p">,</span>
  <span class="n">noseSideLimit_x</span><span class="p">,</span>
  <span class="n">noseSideLimit_y</span><span class="p">,</span>
  <span class="n">earSideLimit_x</span><span class="p">,</span>
  <span class="n">earSideLimit_y</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span> <span class="c"># for backward-compatibility issues</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span>
<span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>nosePoints</strong> provides interesting points positions for the nose (given in camera angles)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">NosePoints</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">bottomCenterLimit_x</span><span class="p">,</span>
  <span class="n">bottomCenterLimit_y</span><span class="p">,</span>
  <span class="n">bottomLeftLimit_x</span><span class="p">,</span>
  <span class="n">bottomLeftLimit_y</span><span class="p">,</span>
  <span class="n">bottomRightLimit_x</span><span class="p">,</span>
  <span class="n">bottomRightLimit_y</span>
<span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>mouthPoints</strong> provides interesting points positions for the mouth (given in camera angles)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">MouthPoints</span> <span class="o">=</span>
<span class="p">[</span>
  <span class="n">leftLimit_x</span><span class="p">,</span>
  <span class="n">leftLimit_y</span><span class="p">,</span>
  <span class="n">rightLimit_x</span><span class="p">,</span>
  <span class="n">rightLimit_y</span><span class="p">,</span>
  <span class="n">topLimit_x</span><span class="p">,</span>
  <span class="n">topLimit_y</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span><span class="p">,</span>
  <span class="n">always_zero</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>Time_Filtered_Reco_Info</strong> can be equal to:</p>
<ul class="simple">
<li>[] if there is nothing new</li>
<li>[ 2, [ faceLabel ] ] if there is one face recognized</li>
<li>[ 3, [ faceLabel0, ..., faceLabelP ] ] if there are several recognized faces</li>
<li>[ 4 ] if a face has been detected for more than 8 seconds without being recognized.
Getting this result is a suggestion to learn this face if desired, but keep in mind
that recognition only works for faces looking towards the robot.</li>
</ul>
<p><strong>CameraPose_InTorsoFrame</strong>: describes the <a class="reference internal" href="../../glossary.html#term-position6d"><span class="xref std std-term">Position6D</span></a> of the camera at the time the image was taken, in <a class="reference internal" href="../../glossary.html#term-frame-torso"><span class="xref std std-term">FRAME_TORSO</span></a>.</p>
<p><strong>CameraPose_InRobotFrame</strong>: describes the <a class="reference internal" href="../../glossary.html#term-position6d"><span class="xref std std-term">Position6D</span></a> of the camera at the time the image was taken, in <a class="reference internal" href="../../glossary.html#term-frame-robot"><span class="xref std std-term">FRAME_ROBOT</span></a>.</p>
<p><strong>Camera_Id</strong>: gives the Id of the camera used for the detection (0 for the top camera, 1 for the bottom camera).</p>
</div>
</div>
<div class="section" id="performances-and-limitations">
<h2>Performances and Limitations<a class="headerlink" href="#performances-and-limitations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="detection">
<h3>Detection<a class="headerlink" href="#detection" title="Permalink to this headline">¶</a></h3>
<p><strong>Performances</strong></p>
<ul class="simple">
<li><strong>Face width</strong>: minimum 20 pixels in the image. For an adult, this corresponds
to around 2 meters in a QVGA image and 4 meters in VGA.</li>
<li><strong>Tilt/Pan</strong>: maximum +/- 15 deg (0 deg corresponding to a face facing the camera)</li>
<li><strong>Rotation</strong> in image plane: maximum +/- 45 deg</li>
</ul>
<p><strong>Limitations</strong></p>
<ul class="simple">
<li><strong>Lighting</strong>: the face detection has been tested under office lightning
conditions - i.e., under 100 to 500 lux. If you feel that the detection is not
running well, try to activate the camera auto gain - via the Monitor
interface - or try to manually adjust the camera contrast.</li>
</ul>
</div>
<div class="section" id="id3">
<h3>Recognition<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><strong>Performances</strong></p>
<ul class="simple">
<li><strong>Face width</strong>: minimum 20 pixels in the image. However, a minimum size
of 40 pixels is recommended for better learning and recognition results.</li>
</ul>
<p>When learning someones face, the subject is supposed to face the camera and to
keep a neutral face because a neutral face is between sadness and happiness.
Otherwise, it would be harder to recognize someone sad if he was smiling during
the learning process.</p>
<p>Sometimes, depending on a change of location or haircut, a known face can be difficult to recognize.
To improve the robustness, a reinforcement process as been added. If someone is not
recognized, or mistaken for someone else, just learn him again. This learning will be
added to that person&#8217;s database. After some days, you should get more reliable recognitions.</p>
<p><strong>Limitations</strong></p>
<p>Recognition is less robust than detection regarding pan, tilt, rotation and maximal distance.
Reason is that the recognition algorithm doesn&#8217;t have a 3D representation of the person to
recognize and uses some info like distances between keypoints for the recognition. If we turn the head,
these distances ratios are modified.</p>
</div>
<div class="section" id="learning">
<h3>Learning<a class="headerlink" href="#learning" title="Permalink to this headline">¶</a></h3>
<p><strong>Performances</strong></p>
<p>The learning stage takes five consecutive images and tries to learn a user&#8217;s
face from each of these images.</p>
<p><strong>Limitations</strong></p>
<p>The learning stage only considers the biggest face found in the field of view.</p>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>Detection<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>To get a feel of what the ALFaceDetection can do, you can use Monitor and launch
the vision plugin. Activate the face detection checkbox and start the camera
acquisition. Then, if you present your face to the camera - or show a picture
with a face on it - Monitor should report the detected faces with blue crosses.</p>
<img alt="../../_images/face_detection_telepathe.png" src="../../_images/face_detection_telepathe.png" />
<p>Another way to use face detection is to launch the Choregraphe <strong>Face Tracker</strong> box.
The robot will try to keep a detected face in the middle of its field of view.</p>
</div>
<div class="section" id="learning-stage-for-recognition">
<span id="alfacedetection-learning-stage"></span><h3>Learning stage for recognition<a class="headerlink" href="#learning-stage-for-recognition" title="Permalink to this headline">¶</a></h3>
<p><strong>Learning stage</strong> can be done via the learnFace bound method of the API or
through user friendly interface of Choregraphe <strong>Learn Face</strong> box.</p>
<ul class="simple">
<li>Once you have clicked on the box and entered the name of the person, this person
has 5 seconds to place its face in front of the robot.</li>
<li>Then the learning process is launched during which the eyes of the robot get blue.<ul>
<li>His eyes turn green in less than a second if the face is seen by the robot in correct
conditions (e.g. no partial shadow on the face, no backlight, person is not too far).</li>
<li>If the eyes are still blue after some seconds, the person should move in order
to change the learning conditions.</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The algorithm requires better conditions for the learning stage than the ones needed
for detection.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can launch the <cite>Face Tracker</cite> box in parallel with the learning stage so the face to
learn is always in the middle of the robot&#8217;s field of view.</p>
</div>
</div>
</div>
</div>


              </div>
            </div>
          </div>
          
            
              <div class="yui-b" id="sidebar">
                
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../contents.html">Site map</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../news/index.html">What’s new</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index_dev_guide.html">NAOqi - Developer guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/index.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/creating_applications/index.html">Creating an application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ref/life/index.html">Programming for a living robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/index_tuto.html">Other tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software/choregraphe/index.html">Choregraphe Suite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dev/programming_index.html">SDKs</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">NAOqi APIs</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../core/index.html">NAOqi Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../interaction/index_interaction.html">NAOqi Interaction engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../motion/index.html">NAOqi Motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../audio/index.html">NAOqi Audio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../vision/index.html">NAOqi Vision</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">NAOqi People Perception</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="alengagementzones.html">ALEngagementZones</a></li>
<li class="toctree-l4"><a class="reference internal" href="alfacecharacteristics.html">ALFaceCharacteristics</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="">ALFaceDetection</a><ul>
<li class="toctree-l5"><a class="reference internal" href="alfacedetection-api.html">ALFaceDetection API</a></li>
<li class="toctree-l5"><a class="reference internal" href="alfacedetection-tuto.html">ALFaceDetection Tutorial</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="algazeanalysis.html">ALGazeAnalysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="alpeopleperception.html">ALPeoplePerception</a></li>
<li class="toctree-l4"><a class="reference internal" href="alsittingpeopledetection.html">ALSittingPeopleDetection</a></li>
<li class="toctree-l4"><a class="reference internal" href="alwavingdetection.html">ALWavingDetection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sensors/index.html">NAOqi Sensors &amp; LEDs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensors/dcm.html">DCM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stdtypes.html">Types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dev/libqi/index.html">qi Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ref/index.html">Former NAOqi Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../simulators/simulator_index.html">Simulators</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../home_nao.html"><strong>NAO</strong> - Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../home_pepper.html"><strong>Pepper</strong> - Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../home_romeo.html"><strong>Romeo</strong> - Documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../legal/notice.html">Legal notices</a></li>
</ul>

    <div id="on-this-page" style="display:none;">
        <h2 id="otp-link">On this page</h2>
        <div id="toc-list">
            <ul>
<li><a class="reference internal" href="#">ALFaceDetection</a><ul>
<li><a class="reference internal" href="#what-it-does">What it does</a></li>
<li><a class="reference internal" href="#how-it-works">How it works</a><ul>
<li><a class="reference internal" href="#face-detection">Face detection</a></li>
<li><a class="reference internal" href="#recognition">Recognition</a><ul>
<li><a class="reference internal" href="#threshold">Threshold</a></li>
<li><a class="reference internal" href="#temporal-filter">Temporal filter</a></li>
</ul>
</li>
<li><a class="reference internal" href="#facedetected-event">FaceDetected Event</a></li>
</ul>
</li>
<li><a class="reference internal" href="#performances-and-limitations">Performances and Limitations</a><ul>
<li><a class="reference internal" href="#detection">Detection</a></li>
<li><a class="reference internal" href="#id3">Recognition</a></li>
<li><a class="reference internal" href="#learning">Learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li><a class="reference internal" href="#id4">Detection</a></li>
<li><a class="reference internal" href="#learning-stage-for-recognition">Learning stage for recognition</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
    </div>
        </div>
      </div>
              </div>
            
          
        </div>
    </main>
    <a href="#0" class="cd-top"></a>
    <div id="ft">
      
      <a title="Glossary" href="../../glossary.html">Glossary</a>
      <a title="Site map" href="../../contents.html">Site map</a>
      <a title="Index" href="../../genindex.html">Index</a>
      <a title="Support" target="_blank" href="https://account.aldebaran.com/support/">Support</a>
      <a title="Contact" target="_blank" href="https://www.aldebaran.com/en/contact">Contact</a>
      <a title="Legal Notices" href="../../legal/notice.html">Legal Notices</a>
      
      
      <img src="https://www.ald.softbankrobotics.com/sites/aldebaran/files/logos-picture/2016_digital_logo_sbr_112x31_0.png" alt="">
    </div>
  </div>

      <div class="clearer"></div>
    </div>
  </body>
</html>