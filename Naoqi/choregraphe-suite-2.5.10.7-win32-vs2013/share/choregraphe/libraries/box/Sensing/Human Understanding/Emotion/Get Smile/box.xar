<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheBox xar_version="3">
    <Box name="root" id="4" localization="8" tooltip="This box returns if the person in front of the robot smiles or not. If a smile is detected, it also returns the smile degree, which can be:&#x0A;- little smile&#x0A;- medium smile&#x0A;- big smile&#x0A;&#x0A;The detection fails when there are more or less than one person in front of the robot or when the timeout is exceeded.&#x0A;&#x0A;It is possible to set up the Confidence Threshold and the Timeout parameters for this box. " x="255" y="304">
        <bitmap>media/images/box/interaction/smile.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        try:
            self.faceC = ALProxy("ALFaceCharacteristics")
        except Exception as e:
            raise RuntimeError(str(e) + "Make sure you're not connected to a virtual robot." )
        self.confidence = self.getParameter("Confidence Threshold")
        self.smileDeg = 0
        self.counter = 0
        self.bIsRunning = False
        self.delayed = []
        self.errorMes = ""

    def onUnload(self):
        self.counter = 0
        self.smileDeg = 0
        self.bIsRunning = False
        self.cancelDelays()

    def onInput_onStart(self):
        try:
            #start timer
            import qi
            import functools
            delay_future = qi.async(self.onTimeout, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))
            self.delayed.append(delay_future)
            bound_clean = functools.partial(self.cleanDelay, delay_future)
            delay_future.addCallback(bound_clean)

            self.bIsRunning = True
            while self.bIsRunning:
                if self.counter < 4:
                    try:
                        #identify user
                        ids = ALMemory.getData("PeoplePerception/PeopleList")
                        if len(ids) == 0:
                            self.errorMes = "No face detected"
                            self.onUnload()
                        elif len(ids) > 1:
                            self.errorMes = "Multiple faces detected"
                            self.onUnload()
                        else:
                            #analyze smile properties
                            self.faceC.analyzeFaceCharacteristics(ids[0])
                            time.sleep(0.1)
                            value = ALMemory.getData("PeoplePerception/Person/"+str(ids[0])+"/SmileProperties")
                            if value[1] > self.confidence:
                                self.smileDeg += value[0]
                                self.counter += 1
                    except:
                        ids = []
                else:
                    #calculate mean value
                    self.smileDeg /= 4
                    if self.smileDeg <= 0.1:
                        self.onNoSmile()
                    elif self.smileDeg > 0.1 and self.smileDeg <= 0.4:
                        self.onSmile("little smile")
                    elif self.smileDeg > 0.4 and self.smileDeg <= 0.8:
                        self.onSmile("medium smile")
                    elif self.smileDeg > 0.8:
                        self.onSmile("big smile")
                    self.onUnload()
                    return
            raise RuntimeError(self.errorMes)
        except Exception as e:
            raise RuntimeError(str(e))
            self.onUnload()

    def onTimeout(self):
        self.errorMes = "Timeout"
        self.onUnload()

    def cleanDelay(self, fut, fut_ref):
        self.delayed.remove(fut)

    def cancelDelays(self):
        cancel_list = list(self.delayed)
        for d in cancel_list:
            d.cancel()

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onSmile" type="3" type_size="1" nature="1" inner="0" tooltip='Returns the smile degree of the person in front of the robot. &#x0A;- &quot;little smile&quot;&#x0A;- &quot;medium smile&quot;&#x0A;- &quot;big smile&quot;&#x0A;&#x0A;Tip:&#x0A;Connect this output to a &quot;Switch Case&quot; box containing the possible output values as strings. In this way you can trigger different paths in your behavior depending on the smile degree.' id="4" />
        <Output name="onNoSmile" type="1" type_size="1" nature="1" inner="0" tooltip="Triggered if no smile is detected" id="5" />
        <Output name="onError" type="3" type_size="1" nature="1" inner="0" tooltip='Triggered when smile detection failed. &#x0A;Possible error messages:&#x0A;- &quot;No face detected&quot;&#x0A;- &quot;Multiple faces detected&quot;&#x0A;- &quot;Timeout&quot;' id="6" />
        <Parameter name="Confidence Threshold" inherits_from_parent="0" content_type="2" value="0.35" default_value="0.6" min="0" max="1" tooltip="Set the confidence threshold for the age detection." id="7" />
        <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="10" default_value="5" min="1" max="60" tooltip="" id="8" />
    </Box>
</ChoregrapheBox>
